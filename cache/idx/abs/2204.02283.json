{"url": "https://arxiv.org/abs/2204.02283", "ref": "2204.02283", "plot": "Lost in Latent Space: Disentangled Models and the Challenge of Combinatorial Generalisation", "image": "images/_pdf_2204.02283.png", "theme": "Artificial Intelligence", "summary": " Recent research has shown that generative models with highly disentangled representations fail to generalise to unseen combination of generative factor values. These findings contradict earlier research which showed improved performance in out-of-training distribution settings when compared to entangled representations. To generalise properly, models not only need to capture factors of variation, but also understand how to invert the generative process that was used to generate the data. They argue that models need to. understand how they are able to. invert."}