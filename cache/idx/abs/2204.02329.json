{"url": "https://arxiv.org/abs/2204.02329", "ref": "2204.02329", "plot": "Can language models learn from explanations in context?", "image": "images/_pdf_2204.02329.png", "theme": "Artificial Intelligence", "summary": " Large language models can perform new tasks by adapting to a few in-context examples. For humans, rapid learning from examples can benefit from explanations that connect examples to task principles. They investigate whether explanations of few-shot examples can allow language models to adapt more effectively. They annotate a set of 40 challenging tasks from BIG-Bench with explanations of answers to a small subset of questions.\n They analyze these results using statistical multilevel modeling techniques that account for nested dependencies among conditions, tasks, prompts, and models. Building a prompt by selecting examples and explanations together substantially improves performance over selecting examples alone. They then show that explanations tuned for performance on a small validation set offer substantially larger benefits.\n Even untuned explanations outperform carefully matched controls, suggesting that the benefits are due to the link between an example and its explanation, rather than lower-level features of the language used. However, only large models can benefit from explanations, according to the study. In-context learning abilities of large language models can support large language learning abilities."}