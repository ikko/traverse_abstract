{"url": "https://arxiv.org/abs/2204.03513", "ref": "2204.03513", "plot": "Many-to-many Splatting for Efficient Video Frame Interpolation", "image": "images/_pdf_2204.03513.png", "theme": "Artificial Intelligence", "summary": " Motion-based video frame interpolation commonly relies on optical flow to warp pixels from the inputs to the desired interpolation instant. They propose a fully differentiable Many-to-Many (M2M) splatting framework to interpolate frames efficiently. Each source pixel renders multiple target pixels and each target pixel can be synthesized from a larger area of visual context. M2M only performs motion estimation once and has a minuscule computational overhead when interpolating an arbitrary number of in-between frames, hence achieving fast multi-frame interpolation."}