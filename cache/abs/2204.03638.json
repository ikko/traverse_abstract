{"url": "https://arxiv.org/abs/2204.03638", "ref": "2204.03638", "plot": "Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer", "image": "images/_pdf_2204.03638.png", "theme": "Artificial Intelligence", "summary": " Videos are created to express emotion, exchange information, and share experiences. Video synthesis has intrigued researchers for a long time. But little progress has been made in generating longer videos. They present a method that builds on 3D-VQGAN and transformers to generate videos with thousands of frames. The evaluation shows that the model trained on 16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse, and Taichi-HD datasets can generate diverse, coherent, and high-quality long videos."}