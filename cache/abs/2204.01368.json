{"url": "https://arxiv.org/abs/2204.01368", "ref": "2204.01368", "plot": "Training Fully Connected Neural Networks is $\\exists\\mathbb{R}$-Complete", "image": "images/_pdf_2204.01368.png", "theme": "Computational Complexity", "summary": " They consider the algorithmic problem of finding the optimal weights and biases for a two-layer fully connected neural network to fit a given set of data points. This problem is known as empirical risk minimization in the machine learning community. They show that the problem is $\\exists\\mathbb{R}$-complete. This complexity class can be defined as the set of algorithmic problems that are polynomial-time equivalent to finding real roots of a polynomorphic polynomic with integer coefficients."}