{"url": "https://arxiv.org/abs/2204.03357", "ref": "2204.03357", "plot": "Parameter-Efficient Abstractive Question Answering over Tables or Text", "image": "images/_pdf_2204.03357.png", "theme": "Computation and Language", "summary": " In this work, they study parameter-efficient abstractive QA in encoder-decoder models over structured tabular data and unstructured textual data. They also ablate over adapter layers in both encoder and decoder modules to study the efficiency-performance trade-off. The models out-perform current state-of-the-art models on tabular QA datasets such as Tablesum and FeTaQA, and achieve comparable performance on a textual QA dataset such as NarrativeQA."}