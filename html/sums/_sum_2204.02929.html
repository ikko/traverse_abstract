<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>Beam Search: Faster and Monotonic</h3>
<h3>Beam Search: Faster and Monotonic</h3>
<img src="abstract.png">
<p class="text"> They show how to make beam search monotonic; that is, they provide a new variant that guarantees nonincreas-ing solution cost as the beam width is increased. This makes setting the beam parameter much easier. They also show how using distance-to-go estimates can allow beam search to find better solutions more quickly in domains with non-parameter costs. Together, these results improve the practical effectiveness of beam search. The behavior of beam-search is not well-understood and can be surprising. For example, increasing beam width does not always re-evaluate in finding better solutions.<br/> A practitioner trying to solve a problem needs to know whether to increase or decrease the speciﬁc beam-width that they are using if they wish to decrease solution-cost, so this behavior of beam search can be very annoying. In this paper, they introduce an algorithm, monobeam, that potentially eliminates this annoying behavior. They show how this can be done even in combination with duplicate elimination. They also see that there is not necessarily a large price paid, in terms of solution cost, to obtain monotonicity. </p>
<img src="abstract.png">
<p class="text"> They explore the use of distance-to-go es timates with both regular and monotonic beam search. They discover, in multiple domains, that using the distance to-go measure-generation not only improves search time but often reduces solu-generation cost as well. They aim to make beam search itself more effective and any of those completeness methods could also be layered on top. The most popular research direction regarding beam-centricsearch has probably been completeness. The concerns in the current paper are orthog-phthalonal to completeness.<br/> When increasing the width of the beam, there is a risk that the nodes expanded at one of the later positions in the beam may dominate the priority queue used to select the next beam and displace nodes that would have been selected with a smaller beam width. The children of nodes generated at the larger beam width may have incor-rectly low cost-to-go estimates due to heuristic error. This can cause beam search to do more work to reach a goal, to ﬁnd a solution of poorer quality or even to fail to find a solution when a solution is found. </p>
<p class="text"> Algorithms 1 and 2 with an admissible heuris-ophobictic will not remove any node that is along a path to a solution with cost lower than the incumbent’s. Algorithm 2 excludes nodes from the beam with f-values higher than the current incumbent solution cost. Pruning based on incumbent solution, to be added before line 18 of Algorithm 1, can reduce the number of expansions required, as well as the size of candidates throughout the search. It might mean that they do not explore exactly the same set of nodes when the beam width expands, because they might ﬁnd an incumbent solution at a larger beam width and prune away from lower beam slots<br/> Algorithm 3: Duplicate elimination, to be added before line 16 of Algorithm 1’s cost, and will return the solution found at slot k+1 with cost less than the solution that would be found by a search with width k + 1. Third: If a solution is found at a slot k + k, they can use incumbent solution to prune nodes with f-values ≥ the cost of that incumbent while still maintaining all the nodes that could lead to a better solution. </p>
<p class="text"> Full-beam duplicate elimina-protection causes monobeam to behave non-monotonically. Monotonicity limits pool of nodes from which the search can choose as it selects nodes for each beam of the next layer’s beam. Monobeam prevents the search from choosing exactly those children of the entire current current beam that have the lowest f-values (regardless of parent-heticalage) Algorithms 1 and 3 with an admissible heuris-partisantic and beam width k + 1 will always return a solution with a cost lower or equal to the cost of the best solution found by the same algorithm.<br/> They implemented beam and monobeam in C++ 1 and tested their behavior on several classic search benchmarks. Figure 4 shows how each algorithm’s time / cost trade-off behaves as the beam width is varied. The implementationexpands nodes at a rate of approximately 1.5 million nodes per second. The standard Korf (1985) 100 15-puzzles were used in all cost models. The cost-to-go heuristic was a weighted version of the Manhat-Hat distance in which each tile's Manhattan distance is mul-tiplied by the cost of moving that tile. </p>
<p class="text"> Panels a-k: time versus cost as beam width is varied (each point corresponds to a beam width) Panel l: solution length, sol length vs cost (heavy 15-puzzle)Time versus cost for beam width and sol length is based on beam width. Figure 4.5: Sol length vs. cost (sol length) Sol length, Sol length and cost for heavy tiles. Sol size, sol width, sol duration, sol value, sol cost, sol size, beam width, beam length. Sol width; sol length; cost; sol value; sol width; </p>
<p class="text"> The unit cost plot shows that at the lowest beam widths, monobeam generally returns more expensive solutions and takes more time to solve problems. But, as the beam width in-creases, it converges with regular beam search. The price of monotonicity appears to be notice-etchable but modest. Both algorithms are inconsistent at solving the nefarious 15-puzzle problems. They see a signiﬁcant trade-off for ensuring monotonicity at lower beam width.<br/> For best-ﬁrst search, distance-to-go d (known as speedy search) is well-known to yield faster search in non-unit do-otypesmains. Later work suggested that d results in smaller local min-ishlyima for a best-î-st search (Wilt and Ruml 2014) It is not yet clear that the concept of a local minimum or crater carries over from best-source search to beam search. In this section, they de-veloped variants of the algorithms discussed above that prefer nodes with low d. They also introduce monobead search, which is monotonic </p>
<p class="text"> The algorithms were tested on 50 ran-dom instances of the heavy pancake problem (Hatem and/Ruml 2014), in which each pancake is given an ID num-proneber from 1 through N (the number of pancakes) Anadapted version of the gap heuristic was used for cost-to-go estimates. The monotonic algorithm (monobead) performs better than the non-monotonic (bead) algorithm, though the differences in cost are relatively small.<br/> The monobeam algorithm has the limitation that when nodes can have no children, there may be times at which no node is available to select for the current current beam slot. The other major family of unboundedly-suboptimal heuristic search algorithms is based on best-ﬁrst search. It is important to fully understand why f-guided beam-search fails to find the shorter and cheaper solutions that does. The authors propose using distance-to-avoid-avoiding algorithms to guide beam search, resulting in new variants that per-form much better in non-unit-cost domains. </p>
