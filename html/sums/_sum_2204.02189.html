<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>Automating Staged Rollout with Reinforcement Learning</h3>
<h3>Automating Staged Rollout with Reinforcement Learning</h3>
<img src="_sum_2204.02189.html.1.png">
<p class="text"> Automating Staged Rollout with Reinforcement Learning. In New Ideas and/or Emerging Results (ICSE-NIERâ€™22), May 21â€“29, 2022, Pittsburgh, PA, USA, 5 pages. Paper demonstrates potential to automate staged rollout with multi-objective reinforcement learning in order to dynamically balance stakeholder needs such as time to deliver new features and downtime incurred by failures due to latent defects. Techniques to automate the staged rollout process could reduce the level of expertise required to balance these stakesholder needs.<br/> This paper presents a model of the staged rollout problem as a non-stationary Markov decision process (MDP) Multi-objective Q-learning with upper confidence bound exploration is applied to solve the MDP. The approach is demonstrated on a data set from the software reliability engineering literature. Additional methods to balance multiple objectives in-cludes geometric steering or hyper volume action selection. The remainder of the paper is organized as follows: Section 2.formulates a state model of a staged rollout process, discussing tradeoffs and reward function modeling. Section 4 develops metrics to assess policies identified by reinforcement learning. Section 5 presents preliminary results. </p>
<img src="_sum_2204.02189.html.2.png">
<p class="text"> The rationale for staged rollout is to publish an updated software possessing new-functionality for use by a subset of the user base. The development team then attempts to correct the source of the problem and begins the process of staged rollout anew. Staged rollout may not be possible to simultaneously minimize down-time and delivery time, posing a multi-objective problem. It is unlikely that a single optimal policy or "one size fits all" ap-proach to staged rollout exists. Instead, it is necessary to select transition times and balance downtime and delivery times.<br/> Traditional software reliability models assume that the rate of defect discovery is nonhomogeneous. The model is non-stationary because the rate at which defects are discovered changes as testing progresses. Staged rollout may be regarded as a modern form of accelerated life testing For example, if the defect detection rate is high in the early stages of testing, then the optimal action will be to stay in the ğ·ğ‘’ğ‘£ state, where the penalty for failure is lowest.<br/>Specifically,<br/>delivery time may be defined as the time to discover and eliminate<br/>defects associated with a test set plus the time to transition from the<br/>ğ·ğ‘’ğ‘£ to ğ‘‚ğ‘ğ‘  state (ğ‘¡ğ·ğ‘’ğ‘£,ğ‘–1 +ğ‘¡ğ‘¡1,ğ‘‚ğ‘ğ‘ ) because no additional defects are<br/>discovered under the simplifying assumption that the final defect is<br/>. </p>
<p class="text"> The suboptimality of a specific policy obtained by an approach with respect to an objective is a factor of the Pareto-front of an approach. Suboptimality is based on the range of the naive approach, which is treated as a baseline for the sake of normalization. It is simply the ratio of the value achieved by a specific objective divided by an equivalent value for the naive-approach when all other objectives are held constant. They approximate suboptimity by linearly interpolating two points on the naive curve in order to obtain a precisely matching value.<br/> Figure 2 compares the range of policies (points) identified by UCB as well as those determined by naive policy enumeration. UCB policies with low delivery times and low downtime greater than 300 are competitive with naive enumeration for downtimes less than 300. Figure 2 also shows that the best policy to minimize downtime that UCB could identify was approximately 70 (upper left most worrisome grey dot on Pareto curve). Tradeoff between downtime and delivery time onYS1 data was about 80% as wide as the corresponding policies. </p>
<p class="text"> The Journal of Machine Learning.Research 17, 1 (2016), 1582â€“1612. The International Symposium on Software Reliability Engineering. will be held May 21â€“29, 2022, Pittsburgh, PA, USA. The conference will be hosted by the IEEE.computing.org, October 21, 2018, and February 28, 2019. For more information on Reinforcement Learning, visit www.i.comprepar.org/reward-reward.com/rewards.org. </p>
