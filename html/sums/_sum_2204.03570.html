<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>Improving Urban Mobility: using artificial intelligence and new technologies to connect supply and demand</h3>
<h3>Improving Urban Mobility: using artificial intelligence and new technologies to connect supply and demand</h3>
<img src="_sum_2204.03570.html.1.png">
<p class="text"> The are of intelligent transportation systems (ITS) aims at investigating how to employ information and communication technologies to problems related to transportation. In the present work, a survey of several works developed by the group are discussed in a holistic perspective, i.e., covering not only the supply side (as commonly found in ITS works), but also the demand side. In this panorama, artiﬁcial intelligence plays an important role, especially with advances in machine learning that translates in the use of computational vision, connected and autonomous vehicles, agent-based simulation, among others. </p>
<img src="_sum_2204.03570.html.2.png">
<p class="text"> Congestion in urban and interurban areas is immense and results in costs that can reach up to 1% of GNP. In 2017, costs were of the order of 300 billion dollars, an increase of 10 billion compared to 2016. “Solutions’ such as tolls, license rotation etc., practiced currently in Brazil, are extremely unpopular. Citizens need to see the return of their sacriﬁce, whether monetary or not. Smart cities emerges, where one focus is on smart urban mobility – as for the rational use of different means of transport. </p>
<p class="text"> Improving Urban Mobility: using artiﬁcial intelligence and new technologies to connect supply and demand have emerged. The ITS (Intelligent Transportation Systems) area has a multidisciplinary character and arose precisely for, among others objectives, to encourage the use of new technologies. The goal of ITS is to develop correct, safe, scalable, persistent, and ubiquitous control systems. However, the decisions of the travelers generate a demand, which translate into route choices, which in turn create a pattern. Travelers may then review their decisions and the cycle is repeated. </p>
<p class="text"> In a transportation network, travellers’ trips are distributed among a set of origin-destination (OD) pairs. The trafﬁc assignment problem (TAP) consists of assigning trips to such routes in an optimal way, given restrictions of capacity and others. In a situation in which each traveller has found the shortest travel time, none has an incentive to change its choice. This state is called user equilibrium, as formulated by Wardrop’s First Principle, which means that all routes have equal costs. The equilibrium state can be dissolved, leading to a greater sum of travel time. </p>
<p class="text"> This section introduces concepts about distributed AI and multiagent systems. In this section, they discuss the use of agent-based simulation (ABS) In ABS, it is possible to model an individual driver’s decision-making, increasing the possibilities of modeling heterogeneity and individuality. This section also introduces concepts such as distributed AI (DAI) and AI-based systems. The section is titled, "Trafﬁc Simulation: Improving Urban Mobility" and new technologies to connect supply and demand. </p>
<p class="text"> Machine learning techniques have found more and more applications in transportation. In the last two decades, interest in new technologies has grown, especially those linked to autonomous vehicles. In parallel, advances in the areas of communication and Internet now allow the so-called autonomous and connected vehicles (CAVs) to communicate with each other. In this way, the system designer does not need to provide the agent with models that require domain knowledge or training instances that are of difﬁcult to obtain. In both cases, agents aim at maximizing their expected rewards. </p>
<p class="text"> The work of does not use reinforcement learning, but, rather, a strategy based on back-pressure to integrate trafﬁcsignals and route choice. The authors in use adaptive tolls to optimize the chosen routes, as the toll fees change. Similarly, deals with the TAP in a centralized perspective to ﬁnd an assignment by imposing tolls on some parts of the network. There are not many works that consider AI in this context. </p>
<p class="text"> This section discusses the main methods proposed and developed by the author. The challenges include the formulation and modeling of multiagent reinforcement learning (MARL), that is, where the presence of more than one agent makes the problem more complex. The fact that there are several agents learning simultaneously in the same environment makes it inherently non-stationary. The solution found is to use scalarization over the multiple objectives, creating a single objective function, which may not be all the same. </p>
<p class="text"> Simulation is heavily employed in trafﬁc and transportation engineering. However, simulation tools are complex and, mostly, available as commercial, closed software. To mitigate this availability issue, the research has built, over 10 years, an open tool called ITSUMO, which pre-dates SUMO. Whereas SUMO is based on car-following, which may be computationally demanding, the development was centered on keeping computational costs low. ItsUMO is a combination of an agent-based model with the Nagel and Schreckenberg cellular automaton model. </p>
<p class="text"> Several methods related to AI and reinforcement learning have been proposed, tested and applied to problems related to traffic control. The main approaches described in and are based on evolutionary game theory and swarm intelligence. The approach was tested with an arterial route located in Porto Alegre. It has been shown that the system. continues to remain stable and adapted to the trafﬁc, without losing its ability to adapt to changes in the environment. The approach. was tested in a arterial, obtaining better performance than a centralized approach classic. </p>
<p class="text"> Mediation-based approach computes more appropriate and ﬂexible coordination groups, as compared to groups found by classical methods. Model-based approaches for reinforcement learning assume the existence of a ﬁxed number of models that supposedly describe the behavior of an environment. Hierarchical multi-agent systems have been proposed to deal with large-scale road networks that may have a high number of learning controller agents, such as trafﬁc signal controllers. In a similar direction, proposes the use of a holonic multi-Agent system to model a road network partitioned into regions (holons) </p>
<p class="text"> This section addresses the demand side of a road network, focusing on how to get from A to B optimally (less time, less cost, etc.) The author has proposed several methods, some pioneers in addressing the disseminationof information via mobile devices when the smartphone did not exist as they know today. Other methods involved: game theory, C2X communication, route choice via reinforcement learning, route recommendation on the alignment of the user and system optimum. An application can be found in. </p>
<p class="text"> There are no precise models for understanding human reasoning on route choice. Classical game theory provides tools for modeling congestion games (Section 2.2) In experiments with human subjects it is possible to observe whether and how they deviate from the results of classical theory. The data collected in these experiments were the basis for the formulation of heuristics for iterative route choice, published in, where a simple form of reinforcement learning simulated the choices that were made by human subjects. This work had important implications because of the typical means of disseminating information was radio broadcast or variable message panels. </p>
<p class="text"> A genetic algorithm exchanges information with a reinforcement learning process that runs at vehicle agents level. This synergy leads to more diverse solutions, which accelerate the convergence of learning, but also lead to more efﬁcient solutions at the global system level. In the proposed model, the road network is treated as a multiagent system, where autonomous vehicles or vehicles plus drivers plus their drivers have their local perception expanded through C2X communication. A further measure was divised, based on the entropy of the distribution of routes, thus taking into account the actual demand in each route. </p>
<p class="text"> The author and colleagues presented several methods proposed to address issues of intelligent control of trafﬁc signals and route choice respectively. The authors suggest that the learning task is achieved quicker through communication rather than sharing the same information for all agents, i.e., co-learning. This way, such a scheme avoids the aforementioned phenomenon where sharing same information can lead to drop in performance. The experiments were carried out using a microscopic simulator and a new approach to the problem of using reinforcement learning in both classes of agents. </p>
<p class="text"> There is a gap with respect to reinforcement learning when agents must make decisions based on multiple objectives. In the case of vehicles, in the real world, their drivers aim not only at minimizing their travel times (as commonly assumed), but also other goals. Figure 3 illustrates this vision with a scheme in which most of the elements have the ability to communicate, either through C2X communication, or through the cloud, or another protocol. The current work is currently focusing on the idea of multiobjective reinforcement learning in urban mobility scenarios. </p>
<p class="text"> The agenda around improving urban mobility is a priority of municipal authorities. Algorithms for multiobjective reinforcement learning are being proposed to address part of this agenda. Classical algorithms for single-agent reinforcement learning such as Q-learning and UCB are being extended and tested in route choice scenarios. Preliminary results show a good performance of the new algorithms, as they achieve the same result as centralized algorithms such as while being faster. It has been shown that it is possible to improve the overall efﬁciency of urban mobility. </p>
