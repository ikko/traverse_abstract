<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>BERTuit: Understanding Spanish language in Twitter through a native transformer</h3>
<h3>BERTuit: Understanding Spanish language in Twitter through a native transformer</h3>
<img src="_sum_2204.03465.html.1.png">
<p class="text"> BERTUIT: UNDERSTANDING SPANISH LANGUAGE in TWITTER. A NEWIVE TRANSFORMERA PREPRINT. BERTuit: Understanding Spanish language in Spanish Twitter using a new multilingual language model. Bertuit is evaluated on several tasks and compared against M-BERT, XLM-RoBERTa. The utility of the approach is shown with a zero-shot methodology to visualize groups of hoaxes and proﬁling authors. </p>
<img src="abstract.png">
<p class="text"> A possible avenue to understand misinformation on social media is to understand its users interactions through the messages they publicly share. This can be done using Natural Language Processing (NLP) techniques, whichremain a powerful approach to understand content delivered in OSNs Farzindar and Inkpen. NLP is able to infer knowledge from stylistic and knowledge characteristics of raw text. BERTuit has been trained with more than 230 million Tweets from the Archive Twitter Stream Grab2, from 2021 to 2018. The result is a transformer model that accurately inherits leanings, nuances and biases from Spanish Twitter.<br/> This improvement at pre-training manages to outperform RoBERTa and XLM-RoBERTa on mono-lingual English tasks. A viable alternative could be found in recent advances such as XLM -Twitter Barbieri et al., where a XL-Twitter model is trained upon a common Crawl website and repository: https://commoncrawl.org/forms/Twitter Stream Grab about page: https://archive.org://://://www.com// </p>
<p class="text"> The model takes approximately 2 weeks to train on a single GPU. The base architecture is the same as BERT-base, with one slight difference on the max input length which has been reduced to 256 tokens. The extended length of 256 tokens has been left for sentence pair tasks such as stance detection, where two twits could be concatenated to perform classiﬁcation. The model is run for 1e6 training steps, the learning rate is scheduled with a warm-up period of 1e4 steps and a later weight decay. </p>
<p class="text"> COVID-19 vaccine has been found to permanently destroy the immune system. The U.S. admitted that only 6% of reported deaths were actually from coronavirus. Drinking lots of water and gargling with hot water and salt eliminates the virus. The use of the mask causes deaths from bacterial pneumonia and bacterial pneumonia. There is a relationship between the Chinese biological laboratory in Wuhan, the pharmaceutical companies Glaxo and Pﬁzer and people like George Soros and Bill Gates.<br/> The number of tweets related to the hoax is N is the number of Tweets related to a hoax. The average and deviation in the test was 0.5%, with the average being 0.3% and 0.4%. The results show that hate speech detection and f1-score are highly likely to be accurate and low-scoring. The test was designed to test the accuracy of hate speech and the f1 score of f1, f2 and f2, f4, f3. </p>
<p class="text"> The arXiv Template has been used to evaluate seven tasks to evaluate. The data is split into a 70/10/20 proportion for training, validation and testing. The tasks have been performed. They have been selected because of their multilingual capabilities, XLM-Twitter-Twitter, because it has been built-in-speciﬁed for its multilingual domain texts, alongside the case of XLMSpeci-Speculation for Twitter-Speculator.<br/> M-BERT is able to recognize 100 languages, with the ability to recognize Spanish among them. XLM-RoBERTa is designed for multi-language pre-training. BERTweet is a model trained with twitter data exclusively, however it is unable to recognize multiple languages. The models described are ﬁne-tuned under the same conditions. For Sequence classiﬁcation tasks Adam optimization is used with a learning rate of 2e-5 during 3 epochs. For token classi-classi-cation added time and rate is needed. </p>
<p class="text"> BERTuit outperforms every other model at most scenarios except POS tagging and token-level sentiment analysis. The time taken to ﬁne-tune each model has also been measured across runs. The most pointed result from the experimentation is that, even some models drop in performance for some domains, while improving on others, the usage of Bertuit remains consistent across all tasks, improving greatly upon the best available baseline or tying against it in the worst case scenario. With this novel tool, they are able to better understand the use of Twitter to understand misinformation, misinformation and countering can be developed.<br/> They aim to provide a simple method to characterize visually the topic of misinformation tweets. They collected >12 thousand tweets supporting 61 popular hoaxes. Each claim is embedded using BERTuit, extracting the second to last hidden state of the claim. A selection of 20 hoaxes and 5 thousand associated claims are selected for a cleaner visualization in a 2D space. A strong enough model should be able to differentiate across topics of misinformation. The analysis focuses mainly on misinformation text to showcase the tool's utility, multimodal architectures are possible. </p>
<p class="text"> Projection of hoaxes, legend represent the hoax number, also marked as crosses over the scatterplot. Number of tweets related to the hoax is N is the number of tweets associated with the hoax. Selection of 20 hoaxes for the visualization. They were extracted in Spanish and, for purposes of this article, they were extracted into Spanish and translated into English. Projections are based on UMAP from the original embeddings. </p>
<p class="text"> The result of projecting hoaxes and tweets is presented on Fig. 2, and the translated hoaxes referenced in the graph are presented on Table 4. Hoaxes are neatly grouped, with the embedding of the hoax among them. This method is not perfect, as some hoaxes are not well positioned, such as hoax 0, 1 or 9, but their related hoaxes maintain some separation from other groups or are grouped with very related topics. At CLEF 2020, a competition was proposed in this line called Proﬁling Fake News Spreaders on Twitter2020 Rangel et al.<br/> The average of the embeddings of each user’s tweet provides the most appropriate representation, reaching a 81,90% accuracy. The use of Bi-LSTM architecture produces a lower result, meaning that this architecture is not able to extract sequential patterns from the data. They follow the same procedure used in previous section to build a 2D projection, in this case through a PCA, given that it shows a better distribution in the distribution in order to improve the previous </p>
<p class="text"> Authors posting real content are placed in the area between -5 and 10 in the horizontal axis and -5 in the vertical axis. Most of the misinformation spreaders are located in this area, but most of them are in other areas. The results show the accuracy of the accuracy according to the number of tweets of each author used during the training phase. The model shows lower rates of accuracy, but just one tweet provides a fruitful information source to label that user, reaching more than 74% accuracy. It can be attributed to the complex language used in Twitter. </p>
<p class="text"> Projection of embedding generated for each author as the mean vector of the embeddings obtained withBERTuit for all the tweets in the test set of the Proﬁling Fake News Spreaders on Twitter 2020 competition. Evaluation of the performance of BERTuit in the detection of Fake News. on Twitter. 2020 competition according to the number of tweets considered for each. author. The embedding was generated by the Bertuit algorithm. </p>
<p class="text"> BERTuit is a language model trained with a RoBERTa optimization in a corpus of 230M tweets in Spanish. The accuracy of the accuracy according to the number of users considered during the training phase has been shown to be a strong correlation between both values. A higher number of tweets does not involve higher accuracy rates. In future work, the goal is to extend the concept of a specialised language model to a multilingual scenario, assessing the ability of these models to understand different languages in this complex domain simultaneously. </p>
