<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>Finding Counterfactual Explanations through Constraint Relaxations</h3>
<h3>Finding Counterfactual Explanations through Constraint Relaxations</h3>
<img src="abstract.png">
<p class="text"> A counterfactual explanation is a type of explanation that can provide a basis for the user to re-evaluate feasibility by helping them understand which changes can be applied to their existing constraints rather than remov-gling them. The need for user-centered explanations in AI has increased due to the black-box nature of complex AI applications, such as the right to explanation of a decision in the EU’s General Privacy Protection Regulations, and the development of Trustworthy AIfor building trust between AI and the society (High-Level Expert Group on AI 2019)<br/> A constraint system aims to solve the course timetabling problem at a university. A lecturer asks the admin: “Why am my Course A scheduled to Friday instead of Monday? I can't attend lectures on Fridays due to travel” The system can provide a counterfactual explanation that explains: ‘If you move Course B from Monday to Tues-to-day, you can schedule Course A on Friday’ Counterfactual explanations have recently been adapted to optimization problems (Korikov, Shleyfman, and Beckorative2021) </p>
<img src="abstract.png">
<p class="text"> In this paper, they propose to adapt counterfactual explanations to constraint-based systems. They then propose a new approach to ﬁnd-ishly-forming a counter-factual explanation based on identifying con ﬂicts and maximal relaxations. Infeasibility in constraint systems may cause an enor-ipientmous cost at an industrial level, which includes customer-centricity. The authors discuss how recent approaches for computing. computing. abductive explanations can beexploited for computing contrastive/counterfactual explana-gui-tions.<br/> Cyras et al. present an extensive overview of various machine reasoning techniques employed in the do-naissancemain of XAI. They discuss XAI techniques from the perspective of symbolic AI. The authors classify explanations into three categories: attributive, contrastive, and actionable explanations. They also discuss the links between these explanations and the existing notions in symbolic AI by covering many different topics such as abductive logic programming, answer set programming, constraint programming, SAT, etc. The authors also high-preciouslight that links between con-ict-detection mechanisms in the XAI and counterfactual explanations is not clear. </p>
<p class="text"> A top element must be deﬁned for each relaxation-space, which corresponds to maximally relaxing the rele-naissancevant constraint (eliminating from the constraint set) Simi-ophobiclarly, a bottom element ⊥ denotes an infeasible state for a given constraint. For in-generation, given an equality constraint such as x = 5, the con-former can be relaxed to x ≤ 5 or x ≥ 5, where the two-state states are incomparable.<br/> For any other problem, the algorithm creates a CSP φ′ with the original set of variables and domains, but uses a constraint set C′ that initially contains only the top elements of each relaxation space for each constraint. Then, the procedure iteratively attempts to tighten the maximal relaxation of each constraint until either the origi-urable user constraint is reached or an inconsistent set of con-oglestraints is formed. In this context, tightening a constraint cipientcorresponds to adding a more restrictive form of c to the ex-existing set of constraints. </p>
<p class="text"> The list of user constraints (c1, c2, c3, c4) and the counterfactual constraint (c5) The user preferences of direc-tions are MIB (more is better) and LIB (“less is better”) The constraints include screen size, memory, battery life, and price. Table 1 lists all available laptops in the solution space. Table 3 presents the relaxation spaces for all constraints, where features are ordered with respect to the user’s preference of direction.<br/> The COUNTER-PFAFACTUALXPLAIN algorithm uses a counterfactual explanation to explain a set of constraints. The algorithm tightens the initial user constraint to ‘Lenovo’, and the constraint tightening is performed for the next constraint. If the user does not have a preference, they assume the direction is the default direction provided by the knowledge engineer. The algorithm returns the maximal relaxation to the given problem with a maximal relaxation. Relaxation spaces for every feature for the data set.<br/> The relaxed CSP φ′ = ⟨X, D, C′⟩ contains a single solution, which is a Lenovo 15.4 inches, 1024.0 MB, 2.2 hr, $1499.99. At this stage, we're only discussing only preliminary research ﬁndings, and the relation of the system to the initial solution is still unclear. The aim in this paper is to create a set of changes that can be applied </p>
