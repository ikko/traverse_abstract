<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>RobustSense: Defending Adversarial Attack for Secure Device-Free Human Activity Recognition</h3>
<img src="_sum_2204.01560.html.1.png">
<p class="text"> Deep neural networks have empowered accurate device-free human activity recognition, which has wide applications. However, these systems could be vulnerable to input perturbations, which can cause accuracy to plummet. They propose a novel learning framework, RobustSense, to defend common attacks.<br/> RobustSense aims to achieve consistent predictions regardless of whether there exists an attack on its input or not, alleviating the negative effect of distribution perturbation caused by adversarial attacks. The results validate that the method works well on wireless human activity recognition and person identiﬁcation systems.<br/> Device-free HAR leverages radar, WiFi and ultrasound for sensor data. Deep learning can be used to extract activities patterns from device-free data. This work has been submitted to the IEEE for possible publication by the University of California, USA.<br/> Deep neural networks are very sensitive to these data perturba-tions. They require powerful computational resources, i.e.Graph Processing Unit (GPU) or Tensor Processing Unit. This situation requires users to transmit sensing data to a cloud server for deep model inference, and then results are returned to user interface via Internet.<br/> Adversarial attacks can fool the deep models to obtain wrong or hacker-deﬁned results, leading to intractable situations in the real world. These attacks have been explored in computer vision research, where severe consequences may be caused by these attacks for face recognition or autonomous driving systems.<br/> It is noted that HAR cybersecurity systems also highly demand safety and security. In smart homes, spiteful tamper of sensing data can deceive the access control system. Illegal manipulation of massive occupancy data hinders the occupancy estimation system, increasing energy-assumption or even triggering emergency equipment such as emergency equipment.<br/> ItarXiv:2204.01560v1 [cs.CR] 4 Apr 2022 4.04 Apr 2022. Itar Xiv: 2204. v1 [csCR] 4Apr 2022 4.04 Apr 4.05 Apr 4. </p>
<img src="_sum_2204.01560.html.2.png">
<p class="text"> The RobustSense framework successfully defends Gaussian noise attack and adversarial attack. Defending attacks boosts model robustness and even achieves better recognition performance. It aims to learn consistent predictions for the raw input and series of simulated attack data, achieving state-of-the-art defense performance.<br/> The contributions of this work are summarized as follows. The work is the ﬁrst that studies the adversarial examples and defense for device-free HAR systems. For HAR situations, they propose a more challenging attack that integrates black-box and white-box attacks, termed as bimodal attack.<br/> The Ro-bustSense offers signiﬁcant improvement of recognition accuracy with a stable training procedure, avoiding cum bersome hyper-parameter tuning process for adversarial training. The device-free HAR sensors are mostly composed of light, ultrasound, radar and radio frequency. These HAR systems usually collect and transmit data to an embedded board or a cloud server for further computations. These systems are vulnerable to adversarial attacks.<br/> WiFi-based sensing leverages existing WiFi infrastrucruc-centrictures for smart sensing, which is cost-effective. It extracts ﬁne-grained Channel State Information (CSI) from multiple WiFi communication (MIMO) WiFi communication links, and enables accurate activity or gesture recognition <br/> CSI data is sampled from Channel.Impulse Response (CIR) h(τ) in Orthogonal Frequency Division.Multiplexing (OFDM) at the physical layer. CSI patterns can be identified by deep neural networks In this sense, different human activities have different CSI patterns, which can be identiﬁed by neural networks. </p>
<p class="text"> The defense capacity of adversarial training is quite limited, especially for the bimodal attack or AL attack. The attacker can build batches of different adversarial examples by simply changing the hyper-parameters, i.eµ, σ in GN and ϵ in FGSM. This can be tackled by manual tuning, but this reduces the availability of such defense especially for unmanned systems.<br/> The objective of the robustSense framework is to confer a signiﬁcant reduction in a potentially deep HAR model’s vulnerability to adversarial examples. Denote the model h(x) as a deep HAR recognition model for wireless CSI data. It is indispensable to conduct supervised learning on normal sensing data.<br/> Perturbation makes a spurious sample by pushing it across the classiﬁcation boundary, successfully deceiving the model h(x) Adversarial examples are generated by perturbing the vulnerable examples near the decision boundary. Deep neural network can thus increase its robustness by having seen these examples before and learn their adversarial distributions.<br/> RobustSense aims to generate consistent predictions. The simplest way is to minimize the cross-entropy loss between the ground-ground-truth label y and all probabilities of adversarial examples. Such objective helps model to adjust its decision boundary to defend adversarial attack. Robust Sense aims to create consistent predictions.<br/> A feasible method is to minimize the sum of the Kullback–Leibler (KL) divergences between each possible pairs of pori and pj.adv. The number of KL loss terms will increase dramatically to Nadv +Nadv (Nadv) as the types of adversarial examples increase.<br/> The number of loss terms is Nadv + 1 and it can be trained effectively in a stable manner due to the usage of a smoother term. By minimizing the JS divergence loss, the RobustSense can be used to minimize the loss of the loss terms by minimizing the divergence loss. </p>
<p class="text"> RobustSense is able to make consistent predictions for the original data sample and various adversarial examples. Two losses are jointly optimized by backpropagation as a multi-task learning. The training procedure is summarized in the training procedure of the Robust Sense. The overall learning objective is formu-ulminminminθf,θg Lce + LJS(xori, ˜xNadvadv,, ˜XNadv(13)<br/> RobustSense framework is a proactive defense-algorithm that prevents potential attacks in the phase of model-training. They generate multiple kinds of adversar-centricial examples by the vanilla model and leverages the consistency loss for augmentation. When the model achieves convergence, the model is robustness to adversarial perturbations.<br/> The RobustSense can use existing adversarial attacks to defend unknown attack-type (i.eϵ, µ, σ) by means of consistency learn-inducinging. The system operates with 40MHz-40GHz bandwidth on 5GHz. The network architecture used in the network architecture is described in Table 1.<br/> Human Activity Recognition (HAR) and gait dataset for Human Identiﬁcation (HID) datasets. Each data sample is a matrix with a size of 3 × 114 × 500. For the HAR dataset, six categories of human activities are collected including running, walking, falling down, boxing, circling arms, and circling arms.<br/> The network design is shown in Table 1 where the feature extractor f(x) is a convolutional neural network. The PyTorchframework is utilized for implementation. They prototype the RobustSense on a server with two NVIDIA RTX 2080Ti GPUs for evaluation.<br/> The networks are optimized by optimizing by using a mini-batch Adam with a learning rate of 0.01 and a momentum-driven momentum of just 0.9. They apply a total epoch of 100 and a batch size of 128 to guarantee sufﬁcient training iterations for the HAR and HID tasks. </p>
<p class="text"> PAPER IN SUBMISSION: Accuracy (%) on HAR dataset under GN attack. The model robustness to a speciﬁc attack. PapER IN SUCLUSIVE: Accuracy. Accuracy (C) is based on the accuracy of a GN attack on the HAR dataset.<br/> They compare the method with the original model without any augmentation, regarded as the baseline model, and the adversarial training methods based on different augmentation losses,, Defense-GAN, MagNet, and Collaborative Multi-Task Training (CMT) <br/> They evaluate the proposed method and compare it with the adversarial training methods on HAR dataset. RobustSense outperforms all other methods, achieving an amaz-tesqueing average accuracy of 98.7% as the noise level of the noise levels increase. The method still shows strong performance with nearly no negative effect.<br/> With a small ϵ = 0.1, the accuracy of the baseline HAR-HID model drops from 96.6% to 35.6%. FGSM attack can even worsen the model performance to an extremely low value that that is worse than the random guess.<br/> AdvT with Ly, LG can help improve the model performance to 94.3% for evaluation under GN attack, but this does not apply to the FGSM situation. RobustSense signiﬁcantly surpasses all other methods, achieving a mean accuracy of 92.6%.<br/> For the most difﬁcult case, the model can achieve an accuracy of 84.5%, outperforming the best comparative model (CMT) by around 18%. Defense-GAN decreases by 8.4% under bimodal attack, which indicates that GAN-based defense approach may not overcome mixtures of attack categories.<br/> RobustSense achieves more stable and consistent results for all noise level τ, σ, while AdvT methods perform poorly for large noise levels. The AdvT method performs better for tough datasets with more activity classes, such as the HAR dataset, which indicates that the Robust Sense has better robustness. </p>
<p class="text"> The RobustSense not only enhances the capacity of model.defense, but also improves the vanilla model performance without attacks. They also have some interesting findings based on the evaluations of two datasets and multiple experimental settings:. The robustness of the Robust Sense has been found to improve the performance of the model.<br/> AdvT achieves 78.4% for HID without attack, less than the baseline of 91.2% by a large margin. RobustSense can always converge well in adversarial training. The best performance does not necessarily stem from employing all adversarial examples, according to the study.<br/> The number and values of hyper-parameters τ, ϵ in defenseand attack might not conform with the real world cases, since de-fender cannot know these settings by attacker. In contrast, the method leverages all adversarial examples and yields the best results with a stable training procedure.<br/> The HAR dataset and the results are shown in Accuracy on the HAR dataset under three types of attacks by random training and testing. Extensive.depth of the data set is shown on Table 8 and Accuracy (%) on HID dataset under FGSM attack at the antenna and subcarrier level.<br/> Most models achieves over 80% accuracy for GN attack, but the performance gets worse for the random attack. RobustSense attains a mean accuracy of 92.8%, outperforming the second place AdvT by over 15%. Local GN attack is too weak, so they only conduct experiments on AL and SL attack via FGSM examples.<br/> As shown in Table 9, the SL attack does not obviously decrease the model performance. The reason is that the subcarrier-level perturbation is too small to threat the model. Even though sensors are partially contaminated, deep models can still make correct predictions based on clean ones. </p>
<p class="text"> The RobustSense can converge across multiple runs, but the AdvT cannot converge. They use SGD and Adam optimizer with an initial learning rate ranging from 0.1 to 0.001. They also evaluate the training stability of the Robust Sense and AdvT.<br/> It is discovered that the cross-entropy loss of FGSM examples are hard to optimize. Figure 3, they visualize the training losses of the method and a stable case of the AdvT. Figure 10 shows the training data and the perturbed data of the same example in HID dataset.<br/> The FGSM example cannot be distinguished from the raw example due to the slight changes induced by FGSM and a super small ϵ. Figure 4 shows that the FGSM attacks can confuse the feature learning of the deep model. Figure 5 shows the feature space of the baseline model and the robustness of the model.<br/> The RobustSense can still preserve important structures of samples in the manifold, which allows the classiﬁer to learn a robust decision boundary. For the baseline method without any defense, there does not exist suf ﬁcient margin for the boundary between two classes.<br/> The RobustSense enhances the defense capacity even in hard situations such as mixtures of attacks. The training of the method is smooth with fast convergence, and the improvements are consistently consistent for various settings and datasets. The approach still brings robustly-improvement, showing the better defense capacity to ad-verselyversarial examples. </p>
<p class="text"> Device-free HAR systems leverage various environment sensors to passively collect human motion patterns, including WiFi, LED light and ultrasound. They overcome shortcomings of device-based HAR systems, e.gIMU, since they do not require users to carry a speciﬁc sensor.<br/> Device-free HAR systems are vulner-able to adversarial attacks. The sensing data can be maliciously-ly-ampered in the IoT embedded system or the communication link to the cloud computation center. Signal processing approaches are good at detecting periodic vital sign or gait activities.<br/> Adversarial attacks have been widely explored in computer vision and natural language processing, e.gface recognition and text classiﬁcation The approachaims to learn consistency between adversarial and normal exam-pledples, which is validated to show superior performance.<br/> Adversarial attacks make an impact on HAR-based HAR models and how to defend the negative effect is a non-trivial task. They provide a comprehensive study on white-box and black-box data attacks for device-free wireless HAR systems. They propose several types of attacks including both white box and black box ones.<br/> Ro-bustSense aims to learn consistent predictions for normal cases and the hazardous cases under various attacks. The results validate that the approach achieves robust performances on two real-world human-human-activity and gait recognition datasets. Visualization further reveals the underlying intuition behind adversarial attacks. </p>
<p class="text"> The current work aims to enhance the model robustness to prevent potential attacks, which belongs to proactive defense. When attacks happen, the model is reckoned to recognize the attacks for record, termed as reactive defense. In the future, they will study reactive defense methods for robust HAR systems that can reject ad-rejection samples from attackers.<br/> Researchers: Robust human activity-recognition using smartphone sensors via ct-pca and online svm. Researchers: “Device-free occupant activity-sensing using wi-enabled iot devices for smart homes.” ‘Device free’ device free human activity recognition,’ in Proceedings of the 24th.Annual International Conference on Mobile Computing and Networking, ‘2018’<br/> Researchers: Towards ubiquitous gait-based human identiﬁcation with wi-scanning technology. Researchers: “Gaitsense’s” aim to be ubiquitous, ‘Gait-free’ and ‘Intriguing properties’ of neural networks.<br/> Researchers: “Expressive 1-lipschitz neural networks for robust multiple graph-graph learning against adversarial attacks.” in International Conference on Machine Learning (PMLR) 2021, pp12 719–12 735. “Adversarial examples: Attacks anddefenses for deep learning,” IJGoodfellow, JShlens, CSzegedy, “Explaining and harnessing’s “advers<br/> Researchers: "Device-free human activity recognition via autoencoder long-term recur-reur-rent convolutional network" "Deepsense" is the latest in a series of articles on computer vision and pattern recognition. The study was published in the Proceedings of the IEEE International Conference on Computer Communications (ICC) "IEEE, 2018, pp1–6"<br/> Researchers: Augmix: A simple data processing method to improve robustness and uncertainty. Researchers: Protecting classiﬁers against adversarial attacks using generative models. They say Augmix is a simple data-processing method that improves uncertainty and robustness.<br/> The IEEE Journal of Selected Areas in Communications, vol35, no5, pp1118–1131, was published in 2017 edition of the Journal of Reviews and Computer Applications, vol. 9, no11, 2008. The IEEE INFOCOM 2018-IEEE Con-agogue on Computer Communications, 2018, pp351–359.<br/> Researchers at the IEEE Internet of Things Journal: “Mobileda: Toward edge-domain adaptation,” “IEEE Transactions on Mobile.computing, 2020. 167, p102738, 2020. Researchers: ‘Environment-robust-device-free human activity recognition with channel-state-informationenhancement and one-shot learning.’<br/> Researchers: Adversarial deep learning for over-the-air spectrum poisoning attacks. Researchers: Learning-empowered attacks in cooperative spectrum sensing. They say this could be used to attack networks such as bert-attackers using a network known as a ‘bert’<br/> Researchers: Intelligent and stealthy attack to wi-ﬁ-based human activity recognition systems. Researchers: "Is-wars" is a stealthy, aggressive attack on wi-disposable and secure computing systems. The researchers: “Suppressing mislabeled data via grouping and self-attention,” in European Conference on Computer Vision. </p>
<p class="text"> Jianfei Yang received the B.Engand Ph.Dfrom the School of Data and Computer Science, SunYat-sen University in 2016, and Nanyang Tech-nological University (NTU), Singapore in 2021. Han Zou is a Presidential postdoctoral Research Fellow and independent PI at NTU.<br/> Xie received the B.Eand M.Edegrees. in 1983 and 1986, and the Ph.D. in 1992. He is currently a Postdoctoral Scholar at the University of Cali gornia, Berkeley, CA, USA. His research interests include ubiquitous computing, statistical learn-orativeing, signal processing and data analytics.<br/> Xie’s research interests include robust control and estimation, networked control systems, multi-agent control and unmanned systems. He has served as an editor of IET Book Series in Control and an associate Editor of a number of journals including IEEE Transactions on Automatic Control, Automatica, IEEE Transactions of Control Systems and Systems-IIDr Xie is a Fellow of Academy of Engineering Singapore. </p>
