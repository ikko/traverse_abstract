<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>Practical Digital Disguises: Leveraging Face Swaps to Protect Patient Privacy</h3>
<h3>Practical Digital Disguises: Leveraging Face Swaps to Protect Patient Privacy</h3>
<img src="_sum_2204.03559.html.1.png">
<p class="text"> The ultimate beneﬁt is improved access to video datasets, e.g. in healthcare settings. Recent literature has proposed deep network-based architectures to perform facial swaps and reported the associated reduction in facial recognition accuracy. They are the ﬁrst to provide a methodology for assessing the privacy-utility trade-offs for the face swapping approach to patient privacy protection. They present an end-to-end pipeline to face swap the faces of the child patients in videos of recorded autismscreening sessions. </p>
<img src="_sum_2204.03559.html.2.png">
<p class="text"> Advances in generative technology have led to a huge advancement in face swapping technology. These algorithms, known as "deep fakes", are able to transpose a character face onto the original face in images or video clips seamlessly, fooling human viewers. Researchers are beginning to harness this tool and apply face swaps in ways that can beneﬁt society There are emerging research topics assessing and improving the privacy protections that face swaps and deidenti-cation guarantee [12, 13, ?].<br/> When context-aware models predict blurred or masked faces, body cues are prioritized and the facial region is largely ignored. These approaches lack control over the resulting identity or consistency when applied to video. Bailer and Winter proposed improvements to DCGAN by applying portrait segmentation on the training data. Segmenting images to replace the background and adding facial structure awareness on top of the discriminator’s unsupervised decision increased the face detection rate of the result. </p>
<p class="text"> The system is a pipelined design that allows multiple video clips to be processed simultaneously while maximizing the system resources on a single machine. It can be divided into two main stages, each with a number of sub-stages, such as face detection and face swap processing. A face detection algorithm provides a list of bounding boxes for detected faces across all frames. A human annotator uses a. GUI to perform multiple tasks: Label regions of time where the key subject is present with face in-frame. (2.) Mark identities not belonging to the. key subject so that they can be ignored in later stages of the pipeline. (3.) Fill in gaps where automatic face detection failed by </p>
<p class="text"> System is divided into automatic face detection, manual corrections via a graphical user interface, and face swap processing (subsectioned into training and deployment) implemented with DeepFaceLab’s code-base. Overall system was divided into. automatic face. detection,. manual corrections, and, face swap. processing, and. face swap training. Automatic face detection and manual corrections. Face swap processing. Face Swap Deployment. </p>
<p class="text"> A real-time or faster processing time is important for this system to be feasibly used in industry. The system is a user interface consisting of fthe passes, three manual and one algorithmic. The full diagram of the full annotations process can be found in Figure 2 and an illustration of the. GUI contents can be seen in Figure 3.2.3.4.5.6.7.9.5. They found that S3FD outperformed MTCNN on the dataset of 4.7 million images. </p>
<p class="text"> In the ﬁrst pass, the annotator goes through the video and marks key frames where the key subject’s face enters or leaves. The second pass is used to supplement additional bounding boxes in the third pass. The fourth pass is an algorithmic interpolation. Annotation typically took between 20-60 minutes per session, depending on session length and the starting accuracy of the automatic face detection algorithm. They use DeepFaceLab (DFL) as the face swapping framework <br/> They provide a methodology for assessing the privacy-utility tradeoff for the face swapping approach. They compute the recognition accuracy of multiple high performing face detection algorithms on the privatized videos, as well as computing three sets of metrics that capture the ﬁdelity of gaze and expression, which are critical cues for autism screening. They also provide the analysis of the accuracy of the face-swapping algorithms on privatized video. They use these metrics to assess the accuracy and reliability of </p>
<p class="text"> They report face detection accuracy in two scenarios: small-scale representation using hand-selected images and large representation using frames from across the full session. In the following analysis, they consider 1/10th of the total number of frames contained in the recorded sessions. Thisreduces the scale of the analysis from 3.2 million faces to approximately 320,000 faces. They report the results on three high-performing face recognition algorithms: Facenet, DeepFace, and ArcFace 7. </p>
<p class="text"> Face swapping was able to consistently double the identity ranking across multiple facial recognition algorithms. They also report the mean index of the original and Deepfakes8 stimuli contained within the FaceForensics++ dataset. The large standard deviations in the identity rankings indicate that facial recognition accuracy is highly variable for in-the-wild. Both before and after manipulation, face swapping is a measure of deidentiﬁcation for the subject’s face. They report these results in Table 4. </p>
<p class="text"> Utility analysis pipeline. Red arrow indicates value comparison and green arrows indicate classiﬁcation. Face recognition results computed across all clinical sessions processed. Detection accuracy is reported at ranks K=1, 2, 5, 10, Median and mean identity rankings. They hypothesize this variation is inﬂuenced by reference dataset size; the 22 individual ADOS set is much lower than the 1000 individual set. A larger reference dataset more sharply decreased recognition accuracy for the face swaps than for the original faces. </p>
<p class="text"> The average Euclidean distance between the landmark points of original and swapped faces is averaged over all 68 key points computed by the Dlib facial landmark predictor. The original face’s O and the deepfake points DF are scaled between 0 and 1 within the bounds of the Face region. They also report the distance separated by key regions (eyes, nose, mouth) by.averaging across select landmark points. They report the percentage of frames considered after threshold-based application and the accuracy of the gaze direction. </p>
