<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>Matrix Polynomial Factorization via Higman Linearization</h3>
<h3>Matrix Polynomial Factorization via Higman Linearization</h3>
<img src="abstract.png">
<p class="text"> A randomized algorithm that runs in time that computes a factorization of 푀 as a matrix product is given by a noncommutative formula of size at most 홙�. They also obtain a deterministic algorithm for the problem with the problem. When F is a ﬁnite, the above result applies. They study the problem of factorization. of matrix polynomials in the free-free-freelylever ring F.1 (Matrix Polynomials)<br/> The matrix ring F⟨푋⟩푑×홙� for 홑 > 1, unlike the matrix ring. The author would like to thank SERB for the funding through the MATRICS project, File no. MTR/2018/001214.1. The MATRics project is a collaboration between SERB and the Institute of Mathematical Sciences, Chennai, India, and Vishwakarma Institute of Technology </p>
<img src="abstract.png">
<p class="text"> Cohn’s factorization theory applies to full matrices. A full matrix in F⟨푋⟩ has noncommutative rank 푑. A full non-unit matrix is an atom if 클 or an atom implies either either oris a unit. They consider the factorization of matrix polynomials over a polyformformform(f) time (they also obtain a deterministic algorithm)<br/> The method is based on Ronyai’s algorithm for computing a nontrivial-common invariant subspace for a collection of matrices which is not known to have an eﬃcient algorithm over rationals [Rón87, FR85] However, the approach works for factorization of matrix polynomials over the univariate ring Q[푥] Unfortunately, they do not have a similar result for matrix poynomials when the underlying underlying is not a common subspace. </p>
<p class="text"> In Section 2 they present the algorithm for factorization of matrix polynomials over the noncommutative ring F푞. In Section 3 they present a deterministic polynomial time algorithm. The algorithm has three broad steps:. Higman linearization of the input matrix. The input matrix 푀 is assumed of full non-unit matrices. The same strategy was used in [AJ22] for the factorization. of the matrix. matrices 큁, is computed by a non-commutatives arithmetic formula of size at most. at most mutable arithmetic formula.<br/> On input a full and right (or left) monic linear matrix 퐿 = a linear matrix atom. There is a randomized polynomial time poly(푛, 푑, log2 ) algorithm to compute a factorization. The problem is a monic matrix atom, where each an atom is a linear matriculous atom. The algorithm is a deterministic time polytime poly((� </p>
<p class="text"> Theorem: Right monic if the matrix has full row rank [Coh06] can be reduced to the factorization of full and right monic linear matrices. This reduction requires a blow-up in the matrix dimension, and that reduction requires 퐴0 to be invertible. This can be computed in deterministic polynomial time using the noncommutative rank algorithm of [IQS18] The algorithm is based on Ronyai’s common invariant subspace.<br/> In [AJ22] they give a deterministic polynomial-time-time algorithm when 퐶 is a linear matrix and 푷 is a matrix of polynomials. In [IQS18] such a matrix-factor substitution is obtained in deterministic time. They require a generalization of this to the case when 큁 is an invertible matrix. The algorithm computes F⟨푋⟩푑×푟 such that their entries are given by algebraic branching programs. </p>
<p class="text"> They reproduce the algorithm from [AJ22]. They describe it as a recursion procedure Trivialize that takes matrix 퐶 and column vector 푣 as parameters and returns the identity matrix. The key additional point to note is that the variable occurs only in 홙�s entry of polynomialsand not in marathoncolumns. The construction of 큁 is such that its entries are only polynomial variables used in the matrix.<br/> The resulting matrix is invertible as it is a product of elementary matrices corresponding to these operations. The only nonzero entry in the matrix is which is in its ﬁrst column. The matrix is called 퐶푇0.0, and the only entry that is not zero is 훼 which is in its threshold. The formula for Trivialize(c) is a matrix returned by the call �. The matrix is resembled (c), and the resulting matrix is </p>
<p class="text"> The matrix 푁 satisﬁes the required property, namely for 1 to 1: for 1. to 0 iﬀ the millennials of a polynomial 큁’s (scalar) coeﬃcient vector is easy to compute in deterministic polynnomine time. The factor extraction algorithm is based on the lemma which will allow us to recover the factors by one by one (Factor Lemma)<br/> Let 푀 ∈ F⟨푋⟩푚×홚 be a matrix polynomial and 푉a unit with a unit that is also an atom, where ℓ = is an atom. Let apologetic‘’� be a unit, where 큉’s ‘-’ is a unit’, or “-”, or “-phenomenic’ – a unit. </p>
<p class="text"> The entries of 푀, 푈, 홉,,, and a nontrivial factorization in deterministic polynomial time. The trivializing algorithm computes a unit whose entries are all given by ABPs such that for 1 to 1 column of (홙) the entries are zero. This implies that the unit 큁 is a unit whose entries are not given as input by ABP.<br/> The ℓ × 푚 matrixhas at least 횚 non-zero rows. The matrix trivializes the relation because the relation is trivialized. The permutation of columns of (횾) is all zeros and the rows of possiblecolumns are nonzero. For example, the column of a column is all zero or the thousands of zeros of a row of allzerosare all nonzero. </p>
<p class="text"> The matrices 퐶′′ = 푶푁Π = 큶 ; 큁’s “porporporation” is a unit; is unit (being upper triangular with all ones diagonal) Since marrarrasions are non-unit matrices, they can drive the matrices (큽) to zero. They can also drive the matrix (큉)to zero; they can then drive a row operation to zero in the matrix.<br/> They conclude that the above algorithm computes a nontrivial factorization of 푀 as a product of a matrix of noncommutative polynomials. There is also a deterministic poly(푠, log) time randomized algorithm for the problem. Theorem: Theorem 2.7.2.3.6.1.2: They apply Higman linearization followed by the linear matrix-factorization algorithm stated in Theorem.2 (see [AJ22] for details) to obtain the factorization. </p>
<p class="text"> Lemma 2.5 is applicable as all conditions are met by the matrices in the above equation. Each linear matrix is an atom, the matrix 푉 is upper triangular with all 1’s diagonal, and the matrix ‘The Higmanization of 큁푟 is computed in determanization time. After leavingthe complete factorization of the input matrices they will have 텅� = (one by one from the right)<br/> For the resulting linear matrix 퐿 = 퐴0 +�푛677푖=1 a product of linear-matrix atoms, its factorization can be computed in randomized poly(푠, �%), deterministicpoly(홙) time as well as in deterministic poly( 홑) time. The overall randomized algorithm has running time poly(), Poly(흠), 큁, �, log2, log3 and log2. </p>
<p class="text"> The problem of factorization of multivariate noncommutative polynomials over Q is not amenable to the approach. In the univariate case they need to compute a nontrivial invariant subspace for a single rational matrix. This gives us a deterministic polynomial-time algorithm for factorizing matrices over Q[푥] The algorithm is to transform the input matrix 푀 into a linear matrix by Higman linearization (see Theorem 2.1)<br/> It turns out that once they have the matrix 퐶 in T-normal form it is easy to compute a trivializing matrix as required. Then they will give a polynomial-time algorithm to transform 푁 into T-Normal form. The algorithm is based on the binary encoding of all integers involved in the matrix. It takes into account the binary encode lengths of all the integers involved. They conclude that the algorithm is a good way to transform the matrix into </p>
<p class="text"> The encoding size of 푎 is the number of bits required to express in binary. For an univariate polynomial 퐶 is, 픟(푟) = max((�ân) ), �âm) for an univariable polynomorphic matrix (Q[푥]), for aunivariatepolicymatrix, the encoding size is, âmantantant(X) for a submatrix of multipolicymantorial Policyant<br/> A linear matrix 퐷 is said to be in T-normal form if its columns are partitioned into three parts, such that the columns are of full column rank. The relation ���rst is easy to trivialize for a matrix 푁 ∈ Q[푥]푟×횟 which is in a T-Normal form. They also have the following Lemma 3.2: A matrix trivializes the relation (퐶푈))(���) = 0 if and only if it trivializes a relation (��) </p>
<p class="text"> The columns of 퐴 are linearly independent, so there is a full rank square submatrix of 퐵. The row indices of 푤 can be subsequently partitioned into [푟] and the row indices partitionedinto [큽1/2/3] and [x] into [X]], where 큁 is an anupper triangular matrix with all diagonal entries 1 and �� = 1.<br/> They describe a polynomial-time algorithm that transforms the input linear matrix 퐶 into a linear matrix in T-normal form. They have shown that the matrix trivializes the relation 푁 trivializes the relation (퐷) = (푷) (큷) The algorithm is called Lemma 3.5. It turns the input matrix into a linear matrix in deterministic time poly(푥) </p>
<p class="text"> They describe the algorithm along with the correctness of each step, side by side. The number of times the while loop executes is bounded by the number of arithmetic operations performed is also bounded by poly-number of operations. They analyze the growth of the coe�ption of the matrices 푵 as algorithm as iterates. They express certain column as linear combination of some other columns as rule they can express. Cramer’s rule can be used to express the polynomially bounding of certain column combinations.<br/> The only step in which a column changes and is used again is when the column 퐵′′′푗0 gets modiﬁed. Crucially, they note that the columns of 퐴 do not cause the change in coeﬃcients of 큵′클큁0. The encoding sizes of all rational numbers involved in the computation remains polynomially bounded in (큽) This completes the proof of the lemma. </p>
<p class="text"> The goal of this subsection is a deterministic polynomial-time algorithm that takes as input a full rank linear matrix 퐿 = and computes a complete factorization of monicmatrix. The algorithm is based on Lemma 3.4 and Lemma 2.5. They prove only the ﬁrst part of the algorithm, the second part follows symmetrically. They compute the T-normal form of the transpose matrix by applying the algorithm of Lemma3.5.<br/> The notions of right and left monic, deﬁned in the multivariate setting [Coh06, AJ22], coincide in the univariate case of monic. They apply the following sets of row/column operations on the matrix [퐴 퐵] to get [통 톴] The set is full rank and the matrix is a matrix of rank magnitudeof rank 푒. The set of </p>
<p class="text"> Using the invertible 푒 × 퐒 scalar submatrix ˆ퐴2 they can perform column operations that drives ˆ possible column operations. The matrix is a full and monic linear matrix with entries that are linear in Q[푥] and entries are linear. They can rewrite the linear matrix as 큿 = 톆1/2/3 and rewrite 턄�1/3 as (큄)/1/4/3/4)<br/> Using standard linear algebra [HK71] they can eﬃciently compute a complete factorization of 퐴 − 푥퐼푑. The problem is equivalent to computing the factorization factoring of Q/Q/X, where Q/X is an invertible matrix. Therefore, setting 클 = − -큼0����−1.1 </p>
<p class="text"> An algorithm that computes a complete factorization of 휒퐴 − 푥퐼푑 into a product of linear matrix atoms. The determinant det(det(�d) is the characteristic polynomial of 혘Deterministic time poly(혟(퓓) of 홙) Theorem 3.9.9: Given as input an invertible matrix Q/Q/X, Q/X: The algorithm works in two phases.<br/> Each linear matrix 퐿푖 is also of the form of 푉햖. The characteristic polynomial and minimal polynomorphism of 클 is an irreducible polynomnimal polynomic. At the bottom of the algorithm, the algorithm is a factorization of each linear matrix of each matrix 'Phenomenon' is a linear matrix factorization. The algorithm is then called 'Phase 2' </p>
<p class="text"> The characteristic polynomial is the power of an irreducible polynomorphism. They deﬁne subspaces 푈푗 is the subspace of vectors annihilated by 푓 (푉) The subspace is a direct sum of many -dimensional sub-spaces. They note that for any nonzero vector 큉 is the so-called cyclicsubspace spanned by the cyclic basis {푢, 퉉,  , ��1 is a good basis.<br/> The matrix 퐵 restricted to 푈1 is block diagonal with 휈1/푘 many blocks, each of size each of size is blockdiagonal. The quotient space is a collection of pairwise disjoint sets of �-dimensional subspace pairs. They generalize this claim to deﬁne a good basis for the quotient. space 큉//x/x: The matrix will be easy to factorize when expressed. </p>
<p class="text"> The bases ℬ|⟩ can all be computed in deterministic polynomial time. They can keep ﬁnding such a cyclic subsets of 푘 vectors as long as they have a proper subspace of of dimension 홙 + 휈푗. The construction of these bases is in deternomial time. The bases are all based on a good basis. Each block will be block diagonal with blocks of size of size.<br/> The middle factor is actually a unit and can be absorbed with either the ﬁrst or the third factor. They present below the steps of the linear matrix factorization algorithm. The algorithm uses the characteristic and minimal polynomials of the matrix 휒퐴(푥) and 푚(횚) to generate the results. The matrix 횴 is in block diagonal form with the characteristic polynomial ‘Phenomenon’. </p>
<p class="text"> 2. Call procedure GoodBasis(퐴푖) which returns a good basis 픅 corresponding to 푴 �d. The basis change matrix has entries of polynomial en-coding size as it is standard Gaussian elimination. They argue that the encoding sizes of the rational numbers involved in the computation are all also polynomially.bounded. In Phase 2, the calls to ProcedureGoodBasis are essentially independentof each other. The computation of some basis ℭ푗 for each subspace 큉 is by standard.<br/> Let 푀 be a matrix of univariate polynomials over rationals where each entry is a polynomial of degree at most 퐷. They apply Higman linearization followed by the monicity algorithm of Lemma 3.8 (second part) and the linear matrix factorization algorithm of Theorem 3.9 to obtain the resultization of the factorizationof Theorem3.9. Each matrixfactor is an atom whose entries are polynomialof degree at most of matrix Q[푥] </p>
<p class="text"> Lemma 2.5 is applicable as all conditions are met by the matrices in the above equation. Each linear matrix is an atom, the matrix is an atom and the entries are all polynomials in Q[푥] of degree at the most most degree at least. The factorization has the following form: 푀 ⊕ 퐼푠 = anatomand 큹푟 is a unit.<br/> The Higman Linearization of 푀 is computed in deterministic polynomial time. At each stage they invoke Lemma 2.5 to extract an atomic factor of reformableatomicfactor. Theorem3.9: By Theorem 3.9 its factorization as a product of linear matrix atoms can be computed in. deterministic time poly(푑, 퐷, 픟(퐿). </p>
