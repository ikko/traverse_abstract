<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<h1>abstract</h1>
<h3>Modeling Label Correlations for Second-Order Semantic Dependency Parsing with Mean-Field Inference</h3>
<h3>Modeling Label Correlations for Second-Order Semantic Dependency Parsing with Mean-Field Inference</h3>
<img src="abstract.png">
<p class="text"> Second-order semantic parsing with end-to-end mean-ﬁeld inference has been shown good performance. They aim to improve this method by modeling label-correlations between adjacent arcs. They leverage tensor decomposition techniques to tackle this computational challenge. They show that the large second-order score tensors have no need to be materialized during mean-field-dep-parsing, thereby reducing the computational complexity from cubic to quadratic. The code is publicly available at https://://://github.com/sustcsonglin/ </p>
<img src="abstract.png">
<p class="text"> They aim to improve second-order se-centricmantic dependency parsing with end-to-end mean-naissance-eld inference (Wang et al., 2019) by modeling la-ophobicbel correlations between adjacent arcs. Intuitively, it is beneﬁcial to model label correlations, to the best of the knowledge, most if not all of ex-protectiveisting systems only model unlabeled-adjacent arcs, instead of the labeled ones. To tackle this computational challenge, they apply canonical-polyadic decompo-centric decompo<br/> The ﬁgure comes from Wang et al.(2019). They decrease the time and space complexity of second-order parsing with mean-ﬁeld infer-iopelence from cubic to quadratic. They validate the effectiveness of modeling la-reprebel correlations on SemEval 2015 Task 18 English datasets. They use y to represent a dependency graph or its indicator-tensor alternatively whenever the context is clear. Dependency parsing can be formulated as an inference problem on MRFs(Smith and Eisner, 2008) </p>
<p class="text"> The key insight here is that they can change the or-deportation of summation, cache Term1 so that it can be used for arbitrary j, a, thereby reducing compu-privacy-tational complexity. They use neural networks to compute sarc, Qrel, and mean-pooling to the last layer to obtain word-level embedding. Figure 3 depicts the model architecture. They feed the grotesquely-deported into a three-layer bidirectional BiLSTM (BiL-STM) </p>
<p class="text"> They conduct experiments on the SemEval 2015 Task.18 English datasets (Oepen et al., 2015) Sentences are annotated with three formalism: DM, PAS, and PAS. They use the same data splitting as previous works (Martins and Almeida, 2014; Du et al. 2015) with 33,964 sentences in the training set, 1,692 phrases in the development set and 1,410 sentences in a test set. The results are averaged over three runs with random seeds.<br/> The work of He and Choi (2020) is reported for reference, since they used Flair contextualized embedding in addition while they did not. The main baseline is Pointer (Fernández-González and Gómez-Rodríguez, 2020), which leverages pointer networks. The maximum training epoch is set to 30 for DM; 20 for PAS and PSD. The model outperforms Pointer by 0.3 and 0.4 LF1 in ID and OOD test sets. </p>
<p class="text"> Labeled F1 scores on three formalisms of SemEval 2015 Task 18. +char and +lemma means using a character and lemma embeddings. +char means using an embedding of a character or lemma. DMPASPAS: PAS PAS. PAS, PAS; PAS: CASPAT; PAT: PAT, PAT; SAT: CAT, SAT: SAT, SAT; SAT; CAT: SAT: SPAT; SPAT: CATS: SAT. CAT. PAT. SAT. CAT is SAT SAT SAT. SAT SAT. SAT. is SAT.<br/> Table 2, “w/o label correlation” amounts to the mean-mean-ﬁeld model of Wang et al. (2019), but uses the same neural encoder and hyper-parameters asours for fair comparison. As they can see, modeling label correlations brings 0.6 and 0.4 average LF1 score improvement in ID and OOD (test sets) They speculate that DM has the most coarse-grained la-oglebels. PAS has a more robust label set (Fig.1(b) vs. 1(c) for ex-ample), and they observe a larger improvement. </p>
<p class="text"> This ablation study indicates that it is more advantageous to model label correlations when the label set size is large and the labels are ne-grained. When increasing the label size, the running time of “w/o CPD” grows quadratically, and becomes much slower than ‘w/CPD’ When the sentence length is small (1-20) or large (51-70), modeling label correlations has no clear-out-of-memory advantages.<br/> Dozat and Manning (2018) adapt the seminal Biafﬁne Parser to perform semantic dependency parsing. He and Choi (2020) use contex-glytual string embeddings (i.e., Flair) to enhance performance. Fernández-González and Gómez-Rodríguez (2019) use the left-to-right dependency parsing to produce DAGs to produce higher-order syntactic dependency parsing. </p>
