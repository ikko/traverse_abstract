<html><head><link rel="stylesheet" href="style.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.0.1/js/bootstrap.min.js" integrity="sha512-EKWWs1ZcA2ZY9lbLISPz8aGR2+L7JVYqBAYTq5AXgBkSjRSuQEGqWx8R1zAX16KdXPaCjOCaKE8MCpU0wcHlHA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script></head>
<body><h1><a href="index.html">abstract</a></h1>
<a class="media" href="https://arxiv.org/abs/2204.03525" target="_blank"><h2>Temporal Alignment for History Representation in Reinforcement Learning</h2><img class="media-object" src="images/_pdf_2204.03525.png"/><p class="media-body"> Inspired by human memory, they propose to represent history with only important changes in the environment. The method (TempAl) aligns temporally-close frames, revealing a general, slowly varying state of the environment. TempAl surpasses the instantaneous-only baseline in 35 environments out of 49. TempAl is based on contrastive loss, which pulls embeddings of nearby observations to each other while pushing away other samples from the batch. It can be interpreted as a metric that captures the temporal relations of observations.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03570" target="_blank"><h2>Improving Urban Mobility: using artificial intelligence and new technologies to connect supply and demand</h2><img class="media-object" src="images/_pdf_2204.03570.png"/><p class="media-body"> The are of intelligent transportation systems (ITS) aims at investigating how to employ information and communication technologies to problems related to transportation. This may mean monitoring and managing the infrastructure (e.g., traffic roads, traffic signals, etc.) However, currently, ITS is also targeting the management of demand. Artificial intelligence plays an important role, especially with the advances in machine learning that translates in the use of computational vision, connected and autonomous vehicles, agent-based simulation, among others. People who are avoiding public transportation are only contributing to an increase in vehicular traffic.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03638" target="_blank"><h2>Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer</h2><img class="media-object" src="images/_pdf_2204.03638.png"/><p class="media-body"> Videos are created to express emotion, exchange information, and share experiences. Video synthesis has intrigued researchers for a long time. But little progress has been made in generating longer videos. They present a method that builds on 3D-VQGAN and transformers to generate videos with thousands of frames. The evaluation shows that the model trained on 16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse, and Taichi-HD datasets can generate diverse, coherent, and high-quality long videos.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03494" target="_blank"><h2>Deep Understanding based Multi-Document Machine Reading Comprehension</h2><img class="media-object" src="abstract.png"/><p class="media-body"> They propose a deep understanding based model for multi-document machine reading comprehension. It has three cascaded deep understanding modules designed to understand the accurate semantic meaning of words, the interactions between the input question and documents, and the supporting cues for the correct answer. They evaluate the model on two large scale benchmark datasets, namely TriviaQA Web and DuReader. Extensive experiments show that the model achieves state-of-the-art results on both datasets. They also demonstrate that the models achieve state-</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03563" target="_blank"><h2>Transfinite Modal Logic: a Semi-quantitative Explanation for Bayesian Reasoning</h2><img class="media-object" src="abstract.png"/><p class="media-body"> Bayesian reasoning plays a significant role in human rationality and machine learning. In this paper, they introduce transfinite modal logic, combining modal and ordinal arithmetic. They argue that in practice, this logic can actually fit into a completely finite interpretation as well. It provides a perfect explanation for Sherlock Holmes' famous saying, "When you have eliminated the impossible, whatever remains, however improbable, must be the truth" They also prove a counterpart of finite model property theorem for the logic.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03592" target="_blank"><h2>Testing the limits of natural language models for predicting human language judgments</h2><img class="media-object" src="images/_pdf_2204.03592.png"/><p class="media-body"> They compared the model-human consistency of diverse language models using a novel experimental approach. For each controversial sentence pair, two language models disagree about which sentence is more likely to occur in natural text. Controversial sentence pairs proved highly effective at revealing model failures and identifying models that aligned most closely with human judgments. The most human-consistent model tested was GPT-2, although experiments also revealed significant shortcomings of its alignment with human perception. The most realistic model tested is GPT 2, but experiments also showed significant shortcomings.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03516" target="_blank"><h2>Distributed Reinforcement Learning for Robot Teams: A Review</h2><img class="media-object" src="images/_pdf_2204.03516.png"/><p class="media-body"> Recent advances in sensing, actuation, and computation have opened the door to multi-robot systems consisting of hundreds/thousands of robots. The community has leveraged model-free multi-agent reinforcement learning (MARL) to devise efficient, scalable controllers. This review aims to provide an analysis of the state-of-the-art in distributed MARL for multi-rob cooperation. The review is focused on the state of the art in distributed MarL for multiboot cooperation.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03559" target="_blank"><h2>Practical Digital Disguises: Leveraging Face Swaps to Protect Patient Privacy</h2><img class="media-object" src="images/_pdf_2204.03559.png"/><p class="media-body"> With rapid advancements in image generation technology, face swapping for privacy protection has emerged as an active area of research. The ultimate benefit is improved access to video datasets, e.g. in healthcare settings. Recent literature has proposed deep network-based architectures to perform facial swaps. However, there is not much reporting on how well these methods preserve the types of semantic information needed for the privatized videos to remain useful for their intended application. The main contribution is a novel end-to-end face swapping pipeline for recorded videos of standardized assessments of autism symptoms in children.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03506" target="_blank"><h2>QCRI's COVID-19 Disinformation Detector: A System to Fight the COVID-19 Infodemic in Social Media</h2><img class="media-object" src="images/_pdf_2204.03506.png"/><p class="media-body"> Fighting the ongoing COVID-19 infodemic has been declared as one of the most important focus areas by the World Health Organization. While the information that is consumed and disseminated consists of promoting fake cures, rumors, and conspiracy theories to spreading xenophobia and panic, at the same time there is information (e.g., containing advice, promoting cure) that can help different stakeholders such as policy-makers. They believe that this will facilitate researchers and different stakeholders. A screencast of the API services and demo is available.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03458" target="_blank"><h2>Video Diffusion Models</h2><img class="media-object" src="images/_pdf_2204.03458.png"/><p class="media-body"> Generating temporally coherent high fidelity video is an important milestone in generative modeling research. They propose a diffusion model for video generation that shows very promising initial results. They present the first results on a large text-conditioned video generation task, as well as state-of-the-art results on an unconditional video generation benchmark. To generate long and higher resolution videos, they introduce a new conditional sampling technique for spatial and temporal video extension that performs better than previously proposed methods. They find to reduce the variance of minibatch gradients and speed up optimization.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03571" target="_blank"><h2>Explicit and Implicit Pattern Relation Analysis for Discovering Actionable Negative Sequences</h2><img class="media-object" src="images/_pdf_2204.03571.png"/><p class="media-body"> Negative sequence analysis (NSA) is to discover negative sequential patterns (NSPs) consisting of important non-occurring and occurring elements and patterns. The limited existing work on NSP mining relies on frequentist and downward closure property-based pattern selection, producing large and redundant NSPs, nonactionable for business decision-making. This work makes the first attempt for actionable NSP discovery. It builds an NSP graph representation, quantify both explicit occurrence-based element and pattern relations.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03508" target="_blank"><h2>A Survey of Multi-task Learning in Natural Language Processing: Regarding Task Relatedness and Training Methods</h2><img class="media-object" src="abstract.png"/><p class="media-body"> Multi-task learning (MTL) has become increasingly popular in natural language processing (NLP) because it improves the performance of related tasks by exploiting their commonalities and differences. It is still not understood very well how multi-task training can be implemented based on the relatedness of training tasks. They present examples in various NLP downstream applications, summarize the task relationships and discuss future directions of this promising topic. They also discuss the role of joint training and multi-step training in NLP.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03503" target="_blank"><h2>Survey on Automated Short Answer Grading with Deep Learning: from Word Embeddings to Transformers</h2><img class="media-object" src="images/_pdf_2204.03503.png"/><p class="media-body"> Automated short answer grading (ASAG) has gained attention in education as a means to scale educational tasks to the growing number of students. Recent progress in Natural Language Processing and Machine Learning has largely influenced the field of ASAG. Deep learning impacted ASAG differently than other fields of NLP, as they noticed that the learned representations alone do not contribute to achieve the best results, but they rather work in a complementary way with hand-engineered features. They structure the analysis of deep learning methods along three categories: word embeddings, sequential models, and attention-based methods.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03610" target="_blank"><h2>Unified Contrastive Learning in Image-Text-Label Space</h2><img class="media-object" src="images/_pdf_2204.03610.png"/><p class="media-body"> Unified Contrastive Learning (UniCL) is an effective way of learning semantically rich yet discriminative representations. It attains gains up to 9.2% and 14.5% in average on zero-shot recognition benchmarks over the language-image contrastive learning and supervised learning methods. In linear probe setting, it also boosts the performance over the two methods by 7.3% and 3.4%. UniCL rivals the methods across three image classification datasets and two types of vision backbones.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03471" target="_blank"><h2>DynLight: Realize dynamic phase duration with multi-level traffic signal control</h2><img class="media-object" src="images/_pdf_2204.03471.png"/><p class="media-body"> Adopting reinforcement learning (RL) for traffic signal control is increasingly popular. Most RL methods use fixed action interval (denoted as tduration) and actuate or maintain a phase every tduration, which makes the phase duration less dynamic and flexible. They propose DynLight-C that adopts a well trained deep Q-network of DynLight and replace M-QL by a fixed cyclical control policy that actuate a set of phases in fixed order to realize cyclical phase structure.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03647" target="_blank"><h2>Adapting CLIP For Phrase Localization Without Further Training</h2><img class="media-object" src="images/_pdf_2204.03647.png"/><p class="media-body"> Supervised or weakly supervised methods for phrase localization (textual grounding) either rely on human annotations or some other supervised models. Obtaining these annotations is labor-intensive and may be difficult to scale in practice. They propose to leverage recent advances in contrastive language-vision models, CLIP, pre-trained on image and caption pairs collected from the internet. They adapt CLIP to generate high-resolution spatial feature maps. Importantly, they can extract feature maps from both ViT and ResNet CLIP model while maintaining semantic properties of an image embedding.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03429" target="_blank"><h2>Finding Counterfactual Explanations through Constraint Relaxations</h2><img class="media-object" src="abstract.png"/><p class="media-body"> Interactive constraint systems often suffer from infeasibility (no solution) due to conflicting user constraints. A counterfactual explanation is a type of explanation that can provide a basis for the user to recover feasibility by helping them understand which changes can be applied to their existing constraints rather than removing them. This approach has been extensively studied in the machine learning field, but requires a more thorough investigation in the context of constraint satisfaction. They propose an iterative method based on conflict detection and maximal relaxations in over-constrained constraint satisfaction problems.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03513" target="_blank"><h2>Many-to-many Splatting for Efficient Video Frame Interpolation</h2><img class="media-object" src="images/_pdf_2204.03513.png"/><p class="media-body"> Motion-based video frame interpolation commonly relies on optical flow to warp pixels from the inputs to the desired interpolation instant. They propose a fully differentiable Many-to-Many (M2M) splatting framework to interpolate frames efficiently. Each source pixel renders multiple target pixels and each target pixel can be synthesized from a larger area of visual context. M2M only performs motion estimation once and has a minuscule computational overhead when interpolating an arbitrary number of in-between frames, hence achieving fast multi-frame interpolation.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03536" target="_blank"><h2>Abstracting Noisy Robot Programs</h2><img class="media-object" src="abstract.png"/><p class="media-body"> Abstraction is a commonly used process to represent some low-level system by a more coarse specification. They describe an approach to abstraction of probabilistic and dynamic systems. They obtain abstract Golog programs that omit unnecessary details and which can be translated back to a detailed program for actual execution. This simplifies the implementation of noisy robot programs, opens up the possibility of using deterministic reasoning methods (e.g., planning) on probabilism problems, and provides domain descriptions that are more easily understandable and explainable.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.03514" target="_blank"><h2>Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale</h2><img class="media-object" src="images/_pdf_2204.03514.png"/><p class="media-body"> They present a large-scale study of imitating human demonstrations on tasks that require a virtual robot to search for objects in new environments. They collect 80k demonstrations for ObjectNav and 12k for Pick&Place, which is an order of magnitude larger than existing human demonstration datasets in simulation or on real robots. They develop a virtual teleoperation data-collection infrastructure -connecting Habitat simulator running in a web browser to Amazon Mechanical Turk, allowing remote users to teleoperate virtual robots, safely and at scale.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.07014" target="_blank"><h2>Rows from Many Sources: Enriching row completions from Wikidata with a pre-trained Language Model</h2><img class="media-object" src="images/_pdf_2204.07014.png"/><p class="media-body"> Row completion is the task of augmenting a given table of text and numbers with additional, relevant rows. They present state-of-the-art results for subject suggestion and gap filling measured on a standard benchmark. They interpret the table using the knowledge base to suggest new rows and generate metadata like headers through property linking. To improve candidate diversity, they synthesize additional rows using free text generation via GPT-3. They exploit the metadata they interpret to produce better prompts for text generation. Finally, they verify that the additional synthesized content can be linked to a trusted web source such as Wikipedia.</p></a>
<a class="media" href="https://arxiv.org/abs/2204.06916" target="_blank"><h2>Should I Follow AI-based Advice? Measuring Appropriate Reliance in Human-AI Decision-Making</h2><img class="media-object" src="images/_pdf_2204.06916.png"/><p class="media-body"> Many important decisions in daily life are made with the help of advisors, e.g., decisions about medical treatments or financial investments. Advice generated by AI is judged by a human and either deemed reliable or rejected. Recent work has shown that AI advice is not always beneficial, as humans have shown to be unable to ignore incorrect AI advice, essentially representing an over-reliance on AI. They propose to view AR as a two-dimensional construct that measures the ability to discriminate advice quality and behave accordingly.</p></a>
